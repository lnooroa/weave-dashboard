name: orchestrator-ai
on:
  issues:
    types: [opened, edited]
permissions:
  contents: write
  pull-requests: write

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Plan → Execute → Fix-once → Comment
        env:
          ISSUE_NUMBER: ${{ github.event.issue.number }}
          ISSUE_TITLE: ${{ github.event.issue.title }}
          ISSUE_BODY: ${{ github.event.issue.body }}
          GH_REPO: ${{ github.repository }}
          GH_TOKEN: ${{ github.token }}
          # ↓ Add this as a repo secret for full autonomy (Settings → Secrets → Actions)
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          # Optional: set if you use a non-OpenAI compatible endpoint
          LLM_BASE_URL: ${{ secrets.LLM_BASE_URL }}
          # Optional: override model (default below is safe + cheap)
          LLM_MODEL: ${{ secrets.LLM_MODEL }}
        shell: bash
        run: |
          set -euo pipefail
          echo "== orchestrator-ai start =="
          title="$ISSUE_TITLE"; body="${ISSUE_BODY:-}"
          if [[ ! "$title" =~ ^(task:|plan:) ]]; then
            echo "No TASK:/PLAN: in title → noop"; exit 0
          fi
          printf "TITLE: %s\n" "$title"
          printf "BODY : %.120s...\n" "$body"

          # ---------- Python driver ----------
          python3 - <<'PY'
          import os, re, json, time, subprocess, pathlib, textwrap, sys, traceback
          from urllib import request as urlreq
          from urllib.error import HTTPError, URLError

          ISSUE_NUMBER = os.environ["ISSUE_NUMBER"]
          TITLE        = os.environ.get("ISSUE_TITLE","")
          BODY         = os.environ.get("ISSUE_BODY","")
          GH_REPO      = os.environ["GH_REPO"]
          GH_TOKEN     = os.environ["GH_TOKEN"]
          LLM_API_KEY  = os.environ.get("LLM_API_KEY","").strip()
          BASE_URL     = (os.environ.get("LLM_BASE_URL") or "https://api.openai.com").rstrip("/")
          MODEL        = os.environ.get("LLM_MODEL") or "gpt-4o-mini"

          root = pathlib.Path(".")
          LOG_DIR = root/".weave"/"logs"; LOG_DIR.mkdir(parents=True, exist_ok=True)
          LOG_FILE = LOG_DIR/f"issue-{ISSUE_NUMBER}.log"

          ALLOW = {"npm","npx","pnpm","yarn","node","bun","echo","printf","mkdir","touch","cp","mv","rm","sed","awk","bash","sh","curl"}

          def log(s):
            print(s, flush=True)

          def allowed(cmd:str)->bool:
            first = (cmd.strip().split() or [""])[0]
            return first in ALLOW

          def run_cmd(cmd:str, timeout=300):
            rc, out = 0, ""
            try:
              p = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)
              rc = p.returncode; out = (p.stdout or "") + (p.stderr or "")
            except subprocess.TimeoutExpired as e:
              rc, out = 124, f"TIMEOUT after {timeout}s\n{e}"
            return rc, out

          def write(path, content):
            p = root/path
            p.parent.mkdir(parents=True, exist_ok=True)
            p.write_text(content, encoding="utf-8")
            return str(p)

          def base_dir():
            for d in ["app","src/app","src/pages","pages"]:
              if (root/d).exists(): return d
            (root/"app").mkdir(exist_ok=True)
            return "app"

          def write_page(slug:str, code:str):
            d = base_dir()
            if "pages" in d: path = f"{d}/{slug.lstrip('/')}.tsx"
            else:            path = f"{d}/{slug.lstrip('/')}/page.tsx"
            return write(path, code)

          def call_llm(title, body, build_error=None, prev_plan=None):
            if not LLM_API_KEY:
              # Deterministic fallback plan (no AI): make a page summarizing the task
              plan = {"steps":[
                {"type":"WRITE","path": write_page("task-summary", f"""export default function Page(){{
  return(<main style={{padding:24,fontFamily:'system-ui, Arial'}}><h1>Task received</h1>
  <pre style={{whiteSpace:'pre-wrap'}}>{json.dumps({'title':title,'body':body})}</pre></main>);}}""")}
              ]}
              return plan, "fallback"
            prompt = textwrap.dedent(f"""
              You are a senior Next.js engineer working in a GitHub Actions worker.
              Project: Next.js (App Router preferred if "app/" exists; otherwise "pages/").
              Respond with STRICT JSON: {{"steps":[...]}} only (no prose).
              Allowed run commands: {sorted(list(ALLOW))}.
              Steps allowed:
              - WRITE: {{"type":"WRITE","path":"<relative path>","content":"<file content>"}}
              - RUN  : {{"type":"RUN","cmd":"<shell command>"}}
              Constraints:
              - Never use interactive prompts; pass flags like --yes.
              - Keep steps minimal and safe. Prefer small diffs.
              - If path is TSX, ensure valid React/Next code (no syntax errors).
              - If a build error is provided, produce a small patch plan to fix it.
              - If using App Router, pages live at app/<slug>/page.tsx. For API: app/api/<name>/route.ts.

              TITLE: {title}
              BODY: {body}
              PREV_PLAN: {json.dumps(prev_plan) if prev_plan else "null"}
              BUILD_ERROR: {json.dumps(build_error) if build_error else "null"}
            """).strip()

            data = {
              "model": MODEL,
              "messages": [
                {"role":"system","content":"Return only JSON. No backticks. Minimal, safe steps."},
                {"role":"user","content": prompt}
              ],
              "temperature": 0.1
            }
            req = urlreq.Request(
              BASE_URL + "/v1/chat/completions",
              data=json.dumps(data).encode("utf-8"),
              headers={
                "Authorization": f"Bearer {LLM_API_KEY}",
                "Content-Type": "application/json"
              }
            )
            try:
              with urlreq.urlopen(req) as r:
                js = json.loads(r.read().decode("utf-8"))
            except HTTPError as e:
              raise RuntimeError(f"LLM HTTP {e.code}: {e.read().decode('utf-8', 'ignore')}")
            except URLError as e:
              raise RuntimeError(f"LLM URL error: {e.reason}")

            content = (js.get("choices") or [{}])[0].get("message",{}).get("content","{}")
            try:
              plan = json.loads(content)
            except json.JSONDecodeError:
              # try to salvage JSON substring
              m = re.search(r'\\{.*\\}\\s*$', content, re.S)
              plan = json.loads(m.group(0)) if m else {"steps":[]}
            return plan, "llm"

          def apply_plan(plan):
            changed = False
            run_logs = []
            for step in plan.get("steps",[]):
              if step.get("type") == "WRITE":
                path = step.get("path","")
                content = step.get("content","")
                # safeguard: avoid writing outside repo
                if ".." in pathlib.Path(path).parts: 
                  run_logs.append(f"SKIP WRITE {path} (unsafe)")
                  continue
                write(path, content)
                changed = True
                run_logs.append(f"WROTE {path} ({len(content)} bytes)")
              elif step.get("type") == "RUN":
                cmd = step.get("cmd","").strip()
                if not allowed(cmd):
                  run_logs.append(f"SKIP RUN {cmd} (not allowed)")
                  continue
                rc,out = run_cmd(cmd, timeout=420)
                run_logs.append(f"RUN {cmd}\\nRC={rc}\\n{out[-2000:]}")
                # mark changed if tools usually mutate repo
                if re.search(r"install|shadcn|add|generate|init", cmd):
                  changed = True
            return changed, run_logs

          def git_commit_if_changed():
            subprocess.run("git add -A", shell=True, check=False)
            rc = subprocess.run("git diff --cached --quiet", shell=True).returncode
            if rc != 0:
              subprocess.run('git config user.name "orchestrator-bot"', shell=True, check=False)
              subprocess.run('git config user.email "orchestrator-bot@users.noreply.github.com"', shell=True, check=False)
              subprocess.run('git commit -m "orchestrator: apply plan"', shell=True, check=False)
              subprocess.run("git push", shell=True, check=False)
              return True
            return False

          def build_once():
            rc,out = run_cmd("npm run build", timeout=600)
            return rc, out

          # --- Phase 1: initial plan ---
          plan1, mode = call_llm(TITLE, BODY, None, None)
          changed, logs1 = apply_plan(plan1)
          committed = git_commit_if_changed()

          # Try to build
          rc, build_out = build_once()
          fix_logs = []
          if rc != 0 and LLM_API_KEY:
            # --- Phase 2: one-shot fix plan ---
            plan2, _ = call_llm(TITLE, BODY, build_out[-4000:], plan1)
            ch2, logs2 = apply_plan(plan2)
            fix_logs = logs2
            committed |= git_commit_if_changed()
            rc, build_out = build_once()

          summary = {
            "mode": mode,
            "plan1": plan1,
            "build_rc": rc,
            "fixed": (rc==0),
          }

          with open(LOG_FILE, "w", encoding="utf-8") as f:
            f.write(f"TITLE: {TITLE}\\n")
            f.write(f"MODE : {mode}\\n")
            f.write("\\n== PLAN 1 ==\\n")
            f.write(json.dumps(plan1, indent=2) + "\\n")
            f.write("\\n== STEP LOGS 1 ==\\n" + "\\n".join(logs1) + "\\n")
            if fix_logs:
              f.write("\\n== FIX LOGS ==\\n" + "\\n".join(fix_logs) + "\\n")
            f.write("\\n== BUILD OUTPUT (tail) ==\\n")
            f.write(build_out[-4000:] if isinstance(build_out, str) else str(build_out))
            f.write(f"\\n== RESULT ==\\nRC={rc}\\n")

          # Comment back to the issue
          try:
            with open(LOG_FILE, "r", encoding="utf-8") as f: content = f.read()
            safe = content.replace("\\","\\\\").replace('"','\\"')
            body = f"**orchestrator-ai summary**\\n\\n```\\n{safe}\\n```"
            url = f"https://api.github.com/repos/{GH_REPO}/issues/{ISSUE_NUMBER}/comments"
            data = json.dumps({"body": body}).encode("utf-8")
            req = urlreq.Request(url, data=data, headers={
              "Authorization": f"Bearer {GH_TOKEN}",
              "Accept": "application/vnd.github+json",
              "Content-Type": "application/json"
            })
            urlreq.urlopen(req).read()
          except Exception as e:
            log(f"Comment error: {e}")

          print("== orchestrator-ai done ==")
          PY
